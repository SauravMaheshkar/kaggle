{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This Notebook is downloaded from Kaggle and is therefore intended to be used as a Kaggle Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34b2bb",
   "metadata": {
    "papermill": {
     "duration": 0.009984,
     "end_time": "2021-10-24T04:51:46.177842",
     "exception": false,
     "start_time": "2021-10-24T04:51:46.167858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📦 Packages and Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f3c546",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-10-24T04:51:46.275463Z",
     "iopub.status.busy": "2021-10-24T04:51:46.274611Z",
     "iopub.status.idle": "2021-10-24T04:52:31.669312Z",
     "shell.execute_reply": "2021-10-24T04:52:31.668638Z",
     "shell.execute_reply.started": "2021-10-24T04:45:46.798085Z"
    },
    "papermill": {
     "duration": 45.482938,
     "end_time": "2021-10-24T04:52:31.669480",
     "exception": false,
     "start_time": "2021-10-24T04:51:46.186542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# -------- Offline Installs -------- #\n",
    "!pip uninstall fsspec -qq -y\n",
    "!pip install -U --no-build-isolation --no-deps ../input/transformers-master/ -qq\n",
    "!pip install --no-index --find-links ../input/hf-datasets/wheels datasets -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0208f8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-10-24T04:52:31.695008Z",
     "iopub.status.busy": "2021-10-24T04:52:31.694208Z",
     "iopub.status.idle": "2021-10-24T04:52:41.395160Z",
     "shell.execute_reply": "2021-10-24T04:52:41.395590Z",
     "shell.execute_reply.started": "2021-10-24T04:46:32.633446Z"
    },
    "papermill": {
     "duration": 9.717476,
     "end_time": "2021-10-24T04:52:41.395805",
     "exception": false,
     "start_time": "2021-10-24T04:52:31.678329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 04:52:37.821250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# -------- Basic Packages -------- #\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "gc.enable()\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn import model_selection\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "# -------- Output Prettification ✨ -------- #\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from transformers import logging\n",
    "logging.set_verbosity_warning()\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# -------- Custom Library -------- #\n",
    "wrapperdir = \"../input/coffee\"\n",
    "sys.path.append(wrapperdir)\n",
    "from coffee.dataloader import Dataset\n",
    "from coffee.helpers import make_model\n",
    "from coffee.data_utils import prepare_test_features\n",
    "from coffee.utils import optimal_num_of_loader_workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d449ddc",
   "metadata": {
    "papermill": {
     "duration": 0.008726,
     "end_time": "2021-10-24T04:52:41.414136",
     "exception": false,
     "start_time": "2021-10-24T04:52:41.405410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📃 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b5979f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T04:52:41.438796Z",
     "iopub.status.busy": "2021-10-24T04:52:41.434190Z",
     "iopub.status.idle": "2021-10-24T04:52:41.440768Z",
     "shell.execute_reply": "2021-10-24T04:52:41.441143Z",
     "shell.execute_reply.started": "2021-10-24T04:46:42.694038Z"
    },
    "papermill": {
     "duration": 0.018276,
     "end_time": "2021-10-24T04:52:41.441265",
     "exception": false,
     "start_time": "2021-10-24T04:52:41.422989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = dict(\n",
    "    # Model\n",
    "    model_type = 'bert',\n",
    "    model_name_or_path = \"../input/muril-large-pt/muril-large-cased\",\n",
    "    config_name = \"../input/muril-large-pt/muril-large-cased\",\n",
    "    output_head_dropout_prob = 0.0, \n",
    "    gradient_accumulation_steps = 2,\n",
    "    # Tokenizer\n",
    "    tokenizer_name = \"../input/muril-large-pt/muril-large-cased\",\n",
    "    max_seq_length = 400,\n",
    "    doc_stride = 135,\n",
    "    # Training\n",
    "    epochs = 1,\n",
    "    folds = 4,\n",
    "    train_batch_size = 2,\n",
    "    eval_batch_size = 8,\n",
    "    # Optimizer\n",
    "    optimizer_type = 'AdamW',\n",
    "    learning_rate = 1.5e-5,\n",
    "    weight_decay = 1e-2,\n",
    "    epsilon = 1e-8,\n",
    "    max_grad_norm = 1.0,\n",
    "    # Scheduler\n",
    "    decay_name = 'cosine-warmup',\n",
    "    warmup_ratio = 0.1,\n",
    "    logging_steps = 100,\n",
    "    # Misc\n",
    "    output_dir = 'output',\n",
    "    seed = 21,\n",
    "    # W&B \n",
    "    competition = 'chaii',\n",
    "    _wandb_kernel = 'sauravm'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aea486",
   "metadata": {
    "papermill": {
     "duration": 0.008291,
     "end_time": "2021-10-24T04:52:41.458030",
     "exception": false,
     "start_time": "2021-10-24T04:52:41.449739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 💿 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f124a3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T04:52:41.480999Z",
     "iopub.status.busy": "2021-10-24T04:52:41.480386Z",
     "iopub.status.idle": "2021-10-24T04:52:42.106589Z",
     "shell.execute_reply": "2021-10-24T04:52:42.106099Z",
     "shell.execute_reply.started": "2021-10-24T04:46:42.704846Z"
    },
    "papermill": {
     "duration": 0.640356,
     "end_time": "2021-10-24T04:52:42.106748",
     "exception": false,
     "start_time": "2021-10-24T04:52:41.466392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\n",
    "base_model_path = '../input/bestmurilchaii/output/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"tokenizer_name\"])\n",
    "\n",
    "test_features = []\n",
    "for i, row in test.iterrows():\n",
    "    test_features += prepare_test_features(CONFIG, row, tokenizer)\n",
    "\n",
    "args = CONFIG\n",
    "test_dataset = Dataset(test_features, mode='test')\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG[\"eval_batch_size\"], \n",
    "    sampler=SequentialSampler(test_dataset),\n",
    "    num_workers=optimal_num_of_loader_workers(),\n",
    "    pin_memory=True, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4db0ce",
   "metadata": {
    "papermill": {
     "duration": 0.010112,
     "end_time": "2021-10-24T04:52:42.127332",
     "exception": false,
     "start_time": "2021-10-24T04:52:42.117220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🔥 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7206dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T04:52:42.155566Z",
     "iopub.status.busy": "2021-10-24T04:52:42.154774Z",
     "iopub.status.idle": "2021-10-24T04:55:02.480426Z",
     "shell.execute_reply": "2021-10-24T04:55:02.479941Z",
     "shell.execute_reply.started": "2021-10-24T04:46:43.390881Z"
    },
    "papermill": {
     "duration": 140.343102,
     "end_time": "2021-10-24T04:55:02.480567",
     "exception": false,
     "start_time": "2021-10-24T04:52:42.137465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "def get_predictions(checkpoint_path):\n",
    "    config, tokenizer, model = make_model(CONFIG)\n",
    "    model.cuda();\n",
    "    model.load_state_dict(\n",
    "        torch.load(base_model_path + checkpoint_path)\n",
    "    );\n",
    "    \n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs_start, outputs_end = model(batch['input_ids'].cuda(), batch['attention_mask'].cuda())\n",
    "            start_logits.append(outputs_start.cpu().numpy().tolist())\n",
    "            end_logits.append(outputs_end.cpu().numpy().tolist())\n",
    "            del outputs_start, outputs_end\n",
    "    del model, tokenizer, config\n",
    "    gc.collect()\n",
    "    return np.vstack(start_logits), np.vstack(end_logits)\n",
    "\n",
    "start_logits1, end_logits1 = get_predictions('checkpoint-fold-0/pytorch_model.bin')\n",
    "start_logits2, end_logits2 = get_predictions('checkpoint-fold-1/pytorch_model.bin')\n",
    "start_logits3, end_logits3 = get_predictions('checkpoint-fold-2/pytorch_model.bin')\n",
    "start_logits4, end_logits4 = get_predictions('checkpoint-fold-3/pytorch_model.bin')\n",
    "\n",
    "start_logits = (start_logits1 + start_logits2 + start_logits3 + start_logits4) / 4\n",
    "end_logits = (end_logits1 + end_logits2 + end_logits3 + end_logits4) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be879555",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-10-24T04:55:02.519861Z",
     "iopub.status.busy": "2021-10-24T04:55:02.508064Z",
     "iopub.status.idle": "2021-10-24T04:55:02.544807Z",
     "shell.execute_reply": "2021-10-24T04:55:02.544338Z",
     "shell.execute_reply.started": "2021-10-24T04:49:11.362407Z"
    },
    "papermill": {
     "duration": 0.054458,
     "end_time": "2021-10-24T04:55:02.544937",
     "exception": false,
     "start_time": "2021-10-24T04:55:02.490479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 5 example predictions split into 50 features.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    \n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    for example_index, example in examples.iterrows():\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None\n",
    "        valid_answers = []\n",
    "        \n",
    "        context = example[\"context\"]\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "\n",
    "            sequence_ids = features[feature_index][\"sequence_ids\"]\n",
    "            context_index = 1\n",
    "\n",
    "            features[feature_index][\"offset_mapping\"] = [\n",
    "                (o if sequence_ids[k] == context_index else None)\n",
    "                for k, o in enumerate(features[feature_index][\"offset_mapping\"])\n",
    "            ]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "        \n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "        \n",
    "        predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        \n",
    "        \n",
    "    return predictions\n",
    "\n",
    "predictions = postprocess_qa_predictions(test, test_features, (start_logits, end_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918e22e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T04:55:02.605457Z",
     "iopub.status.busy": "2021-10-24T04:55:02.604864Z",
     "iopub.status.idle": "2021-10-24T04:55:02.611452Z",
     "shell.execute_reply": "2021-10-24T04:55:02.611907Z",
     "shell.execute_reply.started": "2021-10-24T04:49:11.407563Z"
    },
    "papermill": {
     "duration": 0.056739,
     "end_time": "2021-10-24T04:55:02.612046",
     "exception": false,
     "start_time": "2021-10-24T04:55:02.555307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = []\n",
    "for p1, p2 in predictions.items():\n",
    "    p2 = \" \".join(p2.split())\n",
    "    p2 = p2.strip(punctuation)\n",
    "    submission.append((p1, p2))\n",
    "    \n",
    "sample = pd.DataFrame(submission, columns=[\"id\", \"PredictionString\"])\n",
    "\n",
    "test_data =pd.merge(left=test,right=sample,on='id')\n",
    "\n",
    "bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n",
    "bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n",
    "\n",
    "tamil_ad = \"கி.பி\"\n",
    "tamil_bc = \"கி.மு\"\n",
    "tamil_km = \"கி.மீ\"\n",
    "hindi_ad = \"ई\"\n",
    "hindi_bc = \"ई.पू\"\n",
    "\n",
    "\n",
    "cleaned_preds = []\n",
    "for pred, context in test_data[[\"PredictionString\", \"context\"]].to_numpy():\n",
    "    if pred == \"\":\n",
    "        cleaned_preds.append(pred)\n",
    "        continue\n",
    "    while any([pred.startswith(y) for y in bad_starts]):\n",
    "        pred = pred[1:]\n",
    "    while any([pred.endswith(y) for y in bad_endings]):\n",
    "        if pred.endswith(\"...\"):\n",
    "            pred = pred[:-3]\n",
    "        else:\n",
    "            pred = pred[:-1]\n",
    "    if pred.endswith(\"...\"):\n",
    "            pred = pred[:-3]\n",
    "    \n",
    "    if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n",
    "        pred = pred+\".\"\n",
    "        \n",
    "    cleaned_preds.append(pred)\n",
    "\n",
    "test_data[\"PredictionString\"] = cleaned_preds\n",
    "test_data[['id', 'PredictionString']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c00a303a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T04:55:02.637672Z",
     "iopub.status.busy": "2021-10-24T04:55:02.636876Z",
     "iopub.status.idle": "2021-10-24T04:55:02.651312Z",
     "shell.execute_reply": "2021-10-24T04:55:02.651751Z",
     "shell.execute_reply.started": "2021-10-24T04:49:11.446002Z"
    },
    "papermill": {
     "duration": 0.02955,
     "end_time": "2021-10-24T04:55:02.651883",
     "exception": false,
     "start_time": "2021-10-24T04:55:02.622333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22bff3dec</td>\n",
       "      <td>ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...</td>\n",
       "      <td>ज्वाला गुट्टा की माँ का नाम क्या है</td>\n",
       "      <td>hindi</td>\n",
       "      <td>येलन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282758170</td>\n",
       "      <td>गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...</td>\n",
       "      <td>गूगल मैप्स कब लॉन्च किया गया था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>20 अप्रैल 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d60987e0e</td>\n",
       "      <td>गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...</td>\n",
       "      <td>गुस्ताव किरचॉफ का जन्म कब हुआ था?</td>\n",
       "      <td>hindi</td>\n",
       "      <td>१२ मार्च १८२४</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f99c770dc</td>\n",
       "      <td>அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...</td>\n",
       "      <td>அலுமினியத்தின் அணு எண் என்ன?</td>\n",
       "      <td>tamil</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40dec1964</td>\n",
       "      <td>கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...</td>\n",
       "      <td>இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...</td>\n",
       "      <td>tamil</td>\n",
       "      <td>சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "0  22bff3dec  ज्वाला गुट्टा (जन्म: 7 सितंबर 1983; वर्धा, महा...   \n",
       "1  282758170  गूगल मानचित्र (Google Maps) (पूर्व में गूगल लो...   \n",
       "2  d60987e0e  गुस्ताव रॉबर्ट किरचॉफ़ (१२ मार्च १८२४ - १७ अक्...   \n",
       "3  f99c770dc  அலுமினியம் (ஆங்கிலம்: அலுமினியம்; வட அமெரிக்க ...   \n",
       "4  40dec1964  கூட்டுறவு இயக்க வரலாறு, இங்கிலாந்து  நாட்டில் ...   \n",
       "\n",
       "                                            question language  \\\n",
       "0                ज्वाला गुट्टा की माँ का नाम क्या है    hindi   \n",
       "1                   गूगल मैप्स कब लॉन्च किया गया था?    hindi   \n",
       "2                  गुस्ताव किरचॉफ का जन्म कब हुआ था?    hindi   \n",
       "3                       அலுமினியத்தின் அணு எண் என்ன?    tamil   \n",
       "4  இந்தியாவில் பசுமை புரட்சியின் தந்தை என்று கருத...    tamil   \n",
       "\n",
       "                      PredictionString  \n",
       "0                                 येलन  \n",
       "1                       20 अप्रैल 2010  \n",
       "2                        १२ मार्च १८२४  \n",
       "3                                   13  \n",
       "4  சுவாமிநாதன் மற்றும் வர்கீஸ் குரியன்  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 205.65337,
   "end_time": "2021-10-24T04:55:05.280002",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-24T04:51:39.626632",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
